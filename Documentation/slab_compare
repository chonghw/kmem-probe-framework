
Dynamically allocated kernel strings: a source of fragmentation
---------------------------------------------------------------

Strings, when dynamically allocated, are one of the greatest source
of fragmentation. This is instrinsic to the 'string' nature:
Strings never have a regular size.
String are frequently small, with typical sizes between 4 and 16 (?) bytes.

The (primary?) source of strings is directory entries:
file names, directory names, and such.

Let's compare each allocator and see how they perform.

1. SLOB

SLOB prepends a fixed-size header to every kmalloc allocation.
On x86 this header is 8 bytes long (how about other arches?).

So, if requested string size is between 4 and 16 bytes,
the fragmentation ratio is between 200% and 50%.

SLOB allocator is different from SLAB and SLUB: it doesn't really
implement a 'slab cache' concept. For this reason there is no real
difference between kmallocing 5 bytes or 100 bytes.
The allocator won't search for a cache of a proper size,
but instead just allocate a chunk prepended with a fixed-size header.

Since wastage is independent of requested size, small allocations may
waste a lot, but the wastage falls with increasing allocations.

2. SLUB

When allocating strings SLUB allocator uses its 8, 16 and 32 byte caches.
For requested size between 4 and 16 bytes,
the fragmentation ratio is between 100 and 0%, the worst cases being
4 and 9 bytes, with fragmentation of 100% and 78% respectively.

SLUB being a cache-based allocator, the fragmentation will depend on how aligned
the requested size is to the available size.
For instance, requesting 32 bytes allocates 32 bytes, resulting in zero fragmentation.
Requesting 33 bytes allocates 64 bytes, resulting in 94% fragmentation.

3. SLAB

SLAB operates in a similar way to SLUB, in the sense that allocations are
cache-based and fragmentation depends on fitness between requested size
and cache size.
However, since the smallest SLAB cache is 32 bytes, and strings are typically
much smaller, SLAB is the less efficient of the three.

Just to compare, for requested size between 4 and 16 bytes,
the fragmentation ratio is between 700% and 100%.

Cache objects fragmentation compared
------------------------------------

Cache objects fragmentation occurs when each allocated object needs some extra
bytes for alignment, debug or other metadata. Let's analyze each case.

1. SLOB

Being a very simple allocator, SLOB only needs to reserve extra bytes for
rcu-destroyed objects. 
Currently, each of these objects wastes 12 bytes to store an rcu related struct.

For regular objects the wastage is nil.

It's important to keep in mind that SLOB can leave 'holes' inside slob pages.
These holes are unallocated space that is not lost, because it can
be used if it fits for some requested allocation.

However this means that, on low memory situations, it's possible to run out of memory
for a specific allocation, but still have free space left on these holes.

2. SLAB

If compiled without any debug mechanism (poison, redzone, ...) SLAB allocator
will only reserve extra bytes to return aligned objects.
Of course, the wastage depends on each architecture.

If compiled with debug enabled SLAB will add 24 bytes to each allocated object
for red zoning and user store (see comments in mm/slab.c).

3. SLUB

If compiled without any debug mechanism (poison, redzone, ...) SLUB allocator
will reserve extra bytes for alignment and to store a freelist pointer.

The latter is true only for objects with a defined constructor.
In this case, the wastage is fairly small: only 4/8 bytes (depending on the
architecture) are needed to store a pointer.
However, if many objects are allocated, the wastage can become noticeable.

An example of this is the allocation of inodes. Even on a very minimal system,
more than 1k inodes can get allocated, resulting in a total wastage of 8k bytes.

As with SLAB, if compiled with debug enabled, the allocator adds some extra
bytes to each object for red zoning and user store.
